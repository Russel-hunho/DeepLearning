{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJnhspoNn+s289o258L84A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Russel-hunho/DeepLearning/blob/main/pytorch_Softmax_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://wikidocs.net/59425"
      ],
      "metadata": {
        "id": "vwNHwJa2bVp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**다중 클래스 분류**\n",
        "> 3개 이상의 선택지로부터 1개를 선택하는 문제\n",
        "\n",
        "**소프트맥스(Softmax Regression) 회귀**:\n",
        "> 다중 클래스 분류 문제를 풀기 위한 알고리즘 중 하나"
      ],
      "metadata": {
        "id": "RznIHcEpbZBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 원-핫 인코딩(One-hot Encoding)"
      ],
      "metadata": {
        "id": "l66sGu1LbXAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "원-핫 인코딩: 범주형 데이터의 레이블을 표현하는 방법\n",
        "\n",
        "* 선택하야 하는 선택지의 개수만큼의 차원을 가짐\n",
        "* 각 선택지의 인덱스에 해당하는 원소는 1, 나머지는 0 값을 부여\n",
        "> ex) 3개 선택지: A = [1,0,0]. B = [0,1,0], C = [0,0,1]\n",
        "* 이때, 값을 부여한 벡터 (A,B,C)들을 **원-핫 벡터(one-hot vector)** 라고 한다!\n",
        "* 장점(필요성): **\"관계의 무작위성\" 부여**"
      ],
      "metadata": {
        "id": "uoETDepJcKNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 소프트맥스 회귀 이해\n",
        "다중 클래스 분류(Multi-class Classification)"
      ],
      "metadata": {
        "id": "0AVCYeyIdSrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "X -> Z -> P(예측 벡터) -> Y(결과값, 원-핫 벡터 형식)\n",
        "\n",
        "* [Step1] 입력 X = [x1,x2,...]를, Softmax함수의 입력 Z로 바꾼다!\n",
        "> Z: 답(Y)와 크기가 동일해야함!\n",
        "\n",
        "* [Step2] input Z를 softmax 함수를 적용하여 P 구하기\n",
        "> P: 각 답이 나올 확률벡터; 원소의 총 합 = 1\n",
        "\n",
        "* [step3] P ~ Y간 오차 계산을 통한, softmax 가중치 수정\n",
        "> 적절한 Cost Function: **크로스 엔트로피 함수** 사용!\n",
        ">> cost(W) = - Σ[ (yᵢ)*log(pᵢ) ]\n",
        ">>> 로지스틱(이진분류)에선, y1 = y, y2 = (1-y) 였던 것\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XMvUFfudeErs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.소프트맥스 회귀 비용함수 구현"
      ],
      "metadata": {
        "id": "xmJxHWcnhHM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1. 로우레벨 구현:\n",
        "* F.Softmax 함수 이용 Softmax 적용\n",
        "* torch.log 함수 이용 Cost Function 계산"
      ],
      "metadata": {
        "id": "YxiFKN66petA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "B3_wNiJOcJ9y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.FloatTensor([1,2,3])"
      ],
      "metadata": {
        "id": "pGnZK2qJbU1A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "hypothesis = F.softmax(z, dim = 0) # 첫번째 차원에 소프트맥스 함수를 적용한다는 의미)\n",
        "print(hypothesis) # P 벡터\n",
        "print(hypothesis.sum()) # 합은 1이다!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fTyHWhwhWHv",
        "outputId": "06bdd269-8242-49e7-8f90-773114e6bcee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 연습 data '''\n",
        "\n",
        "torch.manual_seed(1)\n",
        "z = torch.rand(3,5,requires_grad = True) # 3x5 크기의 input, 0~1 사이 random 값\n",
        "print(z)\n",
        "print()\n",
        "\n",
        "''' P값 계산 w/ softmax 함수 '''\n",
        "\n",
        "hypothesis = F.softmax(z, dim = 1)\n",
        "  # 두번째 차원에 소프트맥스 함수 적용)\n",
        "  # 각 샘플(5개 data)에 대해 적용\n",
        "print(hypothesis)\n",
        "\n",
        "for i in range(3):\n",
        "  print(hypothesis[i].sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kiY8W87mT7O",
        "outputId": "73e85d14-9514-4c35-c466-a055fc90c6f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7576, 0.2793, 0.4031, 0.7347, 0.0293],\n",
            "        [0.7999, 0.3971, 0.7544, 0.5695, 0.4388],\n",
            "        [0.6387, 0.5247, 0.6826, 0.3051, 0.4635]], requires_grad=True)\n",
            "\n",
            "tensor([[0.2645, 0.1639, 0.1855, 0.2585, 0.1277],\n",
            "        [0.2430, 0.1624, 0.2322, 0.1930, 0.1694],\n",
            "        [0.2226, 0.1986, 0.2326, 0.1594, 0.1868]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "y = torch.randint(5, (3,)).long()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh5IL7DundKQ",
        "outputId": "85c02882-221d-435f-8277-2a4133b9c7da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 원-핫 인코딩 '''\n",
        "y_one_hot = torch.zeros_like(hypothesis)\n",
        "y_one_hot.scatter_(1, y.unsqueeze(1),1)\n",
        "  # dim = 1 에서 / y.unsqueeze(1)의 원소에 해당하는 위치에 / 1을 넣어라\n",
        "\n",
        "# y의 dim 확장\n",
        "print(y.unsqueeze(1), end=\"\\n\\n\")\n",
        "\n",
        "print(y_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNlAueBn3wY",
        "outputId": "3215bf9b-5cfb-47c9-8a28-255418ae3b06"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0],\n",
            "        [4],\n",
            "        [4]])\n",
            "\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' cost function 계산 '''\n",
        "\n",
        "cost = (-1) * (y_one_hot * torch.log(hypothesis)).sum(dim = 1).mean()\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5D2d7ruo8qs",
        "outputId": "e6afb537-713e-431e-a0b4-1bc81f14dc26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5945, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2. 하이레벨 구현\n",
        "* **F.log_softmax()**: F.softmax() 와 torch.log()를 결합하여, 한번에 계산!\n",
        "* **F.nll_loss()**: F.log_softmax()를 인자로 받아, cost function 계산 식을 한번에 구현!\n",
        "> NLL: Negative Log Likelihood\n",
        "* **F.cross_entropy()**: F.nll_loss()와 F.log_softmax()를 결합하여, 한번에 계산!"
      ],
      "metadata": {
        "id": "JSC1w05RhXG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연습 data\n",
        "z = torch.rand(3,5,requires_grad = True) # 3x5 크기의 input, 0~1 사이 random 값\n",
        "y = torch.randint(5, (3,)).long()\n",
        "y_one_hot = torch.zeros_like(hypothesis)\n",
        "y_one_hot.scatter_(1, y.unsqueeze(1),1)\n",
        "\n",
        "# Low Level 방식\n",
        "print( torch.log(F.softmax(z,dim = 1)) )\n",
        "cost = (-1)*( y_one_hot * torch.log(F.softmax(z,dim=1)) ).sum(dim=1).mean()\n",
        "print(cost , end = \"\\n\\n\")\n",
        "''' = \n",
        "hypothesis = F.softmax(z,dim = 1)\n",
        "cost = (-1) * ( y_one_hot * torch.log(hypothesis) ).sum(dim=1).mean()\n",
        "'''\n",
        "\n",
        "# torch.log와 torch.softmax를 한번에 계산\n",
        "print( torch.log_softmax(z,dim=1) )\n",
        "cost = (-1)*( y_one_hot * F.log_softmax(z,dim=1) ).sum(dim=1).mean()\n",
        "print(cost , end = \"\\n\\n\")\n",
        "\n",
        "# Cost 계산식을 F.nll_loss로 계산\n",
        "cost = F.nll_loss( F.log_softmax(z,dim=1), y)\n",
        "print(cost , end = \"\\n\\n\")\n",
        "\n",
        "# High Level 방식\n",
        "# cross_entropy로 cost를 한번에 계산\n",
        "cost = F.cross_entropy(z,y)\n",
        "print(cost , end = \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZebpuXPupih6",
        "outputId": "9e47b04d-53a6-4396-eee1-0c0836de0482"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.4574, -2.1628, -1.3922, -1.7949, -1.4377],\n",
            "        [-1.6144, -1.7452, -1.5452, -1.6593, -1.5013],\n",
            "        [-1.7669, -1.6085, -1.6170, -1.4995, -1.5740]], grad_fn=<LogBackward0>)\n",
            "tensor(1.6347, grad_fn=<MulBackward0>)\n",
            "\n",
            "tensor([[-1.4574, -2.1628, -1.3922, -1.7949, -1.4377],\n",
            "        [-1.6144, -1.7452, -1.5452, -1.6593, -1.5013],\n",
            "        [-1.7669, -1.6085, -1.6170, -1.4995, -1.5740]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor(1.6347, grad_fn=<MulBackward0>)\n",
            "\n",
            "tensor(1.6347, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "tensor(1.6347, grad_fn=<NllLossBackward0>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 소프트맥스 회귀 구현"
      ],
      "metadata": {
        "id": "I2PeOKLmurHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 공통 전처리\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#시드 고정\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# 훈련 데이터 설정\n",
        "x_train = [[1, 2, 1, 1],\n",
        "           [2, 1, 3, 2],\n",
        "           [3, 1, 3, 4],\n",
        "           [4, 1, 5, 5],\n",
        "           [1, 7, 5, 5],\n",
        "           [1, 2, 5, 6],\n",
        "           [1, 6, 6, 6],\n",
        "           [1, 7, 7, 7]]\n",
        "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "\n",
        "\n",
        "# y_one_hot 구현\n",
        "'''\n",
        "y는 8개의 data이지만, 범주로는 [0,1,2] 3개의 data를 갖는다\n",
        "-> X(8x4) -> Y_one-hot(8x3) -> Y(8)\n",
        "'''\n",
        "y_one_hot = torch.zeros(8,3)\n",
        "y_one_hot.scatter_(1,y_train.unsqueeze(1),1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVVVc2ojuthe",
        "outputId": "2c33344f-a141-45d3-9b4e-8b02ef8878d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1.],\n",
              "        [0., 0., 1.],\n",
              "        [0., 0., 1.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [1., 0., 0.],\n",
              "        [1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1. 로우레벨 모델 구현\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vmon4653vfkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 para 설정\n",
        "W = torch.zeros((4,3), requires_grad = True)\n",
        "b = torch.zeros((1,3), requires_grad = True)\n",
        "\n",
        "# Optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr = 0.01)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(X) = softmax( WX + B )\n",
        "  hypothesis = F.softmax( x_train.matmul(W) + b, dim = 1 )\n",
        "\n",
        "  # cost\n",
        "  cost = (-1) * ( y_one_hot * hypothesis ).sum(dim=1).mean()\n",
        "\n",
        "  # 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 로그 출력\n",
        "  if epoch%100 == 0:\n",
        "    print(\"Epoch: {:4d}/{}, Cost: {:.6f}\".format(\n",
        "        epoch, nb_epochs, cost.item()\n",
        "    ), end = \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ivN-8mvajH",
        "outputId": "40e43a08-f3a3-48cb-9ae7-6ee5dc78e2d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    0/1000, Cost: -0.333333\n",
            "Epoch:  100/1000, Cost: -0.412803\n",
            "Epoch:  200/1000, Cost: -0.457824\n",
            "Epoch:  300/1000, Cost: -0.491296\n",
            "Epoch:  400/1000, Cost: -0.517861\n",
            "Epoch:  500/1000, Cost: -0.540541\n",
            "Epoch:  600/1000, Cost: -0.560789\n",
            "Epoch:  700/1000, Cost: -0.579231\n",
            "Epoch:  800/1000, Cost: -0.596110\n",
            "Epoch:  900/1000, Cost: -0.611523\n",
            "Epoch: 1000/1000, Cost: -0.625530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2. 하이레벨 구현"
      ],
      "metadata": {
        "id": "d_umg-Sbvigb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model 설정\n",
        "W = torch.zeros((4,3), requires_grad = True)\n",
        "b = torch.zeros((1,3), requires_grad = True)\n",
        "\n",
        "# Optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr = 0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  \n",
        "  # Z 구현\n",
        "  z = x_train.matmul(W)+b\n",
        "  \n",
        "  # Cost 계산\n",
        "  cost = F.cross_entropy(z, y_train)\n",
        "\n",
        "  # 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 100번마다 로그 출력\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfsDup3mvljG",
        "outputId": "371e3612-151c-476b-ca4b-1d6967bcb097"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.098612\n",
            "Epoch  100/1000 Cost: 0.704199\n",
            "Epoch  200/1000 Cost: 0.623000\n",
            "Epoch  300/1000 Cost: 0.565717\n",
            "Epoch  400/1000 Cost: 0.515291\n",
            "Epoch  500/1000 Cost: 0.467662\n",
            "Epoch  600/1000 Cost: 0.421278\n",
            "Epoch  700/1000 Cost: 0.375401\n",
            "Epoch  800/1000 Cost: 0.329766\n",
            "Epoch  900/1000 Cost: 0.285073\n",
            "Epoch 1000/1000 Cost: 0.248155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.3. nn.Module로 구현"
      ],
      "metadata": {
        "id": "0Xl7pXxvB-IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(4,3)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(X)\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  # Cost\n",
        "  cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "  #개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 20번마다 로그 출력\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GszbD3vB932",
        "outputId": "4286e9ac-9d7e-4231-f929-edf8daaa73ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.616785\n",
            "Epoch  100/1000 Cost: 0.658891\n",
            "Epoch  200/1000 Cost: 0.573443\n",
            "Epoch  300/1000 Cost: 0.518151\n",
            "Epoch  400/1000 Cost: 0.473265\n",
            "Epoch  500/1000 Cost: 0.433516\n",
            "Epoch  600/1000 Cost: 0.396563\n",
            "Epoch  700/1000 Cost: 0.360914\n",
            "Epoch  800/1000 Cost: 0.325392\n",
            "Epoch  900/1000 Cost: 0.289178\n",
            "Epoch 1000/1000 Cost: 0.254148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.4. Class로 구현"
      ],
      "metadata": {
        "id": "BFP6M1D-CiXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(4,3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "metadata": {
        "id": "u8zJDCntChvD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  \n",
        "  #H(X)\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  #Cost\n",
        "  cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "  #개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # log 출력\n",
        "  if epoch%100 == 0:\n",
        "    print(\"Epoch: {:4d}/{}, Cost: {:.4f}\".format(\n",
        "        epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyQigH4xC2Un",
        "outputId": "90dcf0ed-2ebf-4d2d-ebb7-13177d9f60e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    0/1000, Cost: 2.6376\n",
            "Epoch:  100/1000, Cost: 0.6479\n",
            "Epoch:  200/1000, Cost: 0.5646\n",
            "Epoch:  300/1000, Cost: 0.5110\n",
            "Epoch:  400/1000, Cost: 0.4672\n",
            "Epoch:  500/1000, Cost: 0.4283\n",
            "Epoch:  600/1000, Cost: 0.3919\n",
            "Epoch:  700/1000, Cost: 0.3567\n",
            "Epoch:  800/1000, Cost: 0.3216\n",
            "Epoch:  900/1000, Cost: 0.2856\n",
            "Epoch: 1000/1000, Cost: 0.2508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Softmax 회귀로 MNIST 데이터 분류하기"
      ],
      "metadata": {
        "id": "ER-SvgNFEeSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "utJwC9P1Ejvt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 활성화\n",
        "USE_CUDA = torch.cuda.is_available() # cuda(GPU) 사용 가능하면 True, 아니면 False\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"다음 기기로 학습합니다:\", device )\n",
        "\n",
        "# GPU SEED 고정\n",
        "torch.cuda.manual_seed_all(777)\n",
        "\n",
        "# HYperparameter 설정\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCNx7gDaStCP",
        "outputId": "b0c473a4-b21c-40be-c543-221015939fe5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 기기로 학습합니다: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' MNIST Data 불러오기 '''\n",
        "# 훈련용 data\n",
        "mnist_train = dsets.MNIST(root = \"MNIST_data/\",\n",
        "                          train = True,\n",
        "                          transform = transforms.ToTensor(),\n",
        "                          download = True)\n",
        "\n",
        "# test용 data\n",
        "mnist_test = dsets.MNIST(root = \"MNIST_data\",\n",
        "                          train = False,\n",
        "                          transform = transforms.ToTensor(),\n",
        "                          download = True)"
      ],
      "metadata": {
        "id": "4t6w9GKqTUjp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Dataset 미니배치화 '''\n",
        "data_loader = DataLoader(dataset = mnist_train, \n",
        "                         batch_size = batch_size, #100\n",
        "                         shuffle = True,\n",
        "                         drop_last = True\n",
        "                         # batch_size로 나눈 나머지(마지막 배치)의 학습 사용 여부; drop하겠다!\n",
        "                         )\n",
        "                  "
      ],
      "metadata": {
        "id": "lyzCuxEiUBN7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 모델 설계 '''\n",
        "linear = nn.Linear(784, 10, bias = True).to(device)\n",
        "  # 784 = 28*28, MNIST data 이미지는 28*28 픽셀 이미지이다\n",
        "  # device = gpu로 계산해라"
      ],
      "metadata": {
        "id": "qWO0saAtUtBC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.1)\n",
        "\n",
        "# Cost Function\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "  # 소프트맥스 함수가 포함됨\n",
        "  # torch.nn.functional.cross_entropy()와 거의 유사"
      ],
      "metadata": {
        "id": "dfSfvuuvVt9a"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 학습 '''\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  total_batch = len(data_loader)\n",
        "\n",
        "  # 미니배치 학습\n",
        "  for  X,Y in data_loader:\n",
        "    X = X.view(-1, 28*28).to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    hypothesis = linear(X)\n",
        "    cost = criterion(hypothesis, Y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "  \n",
        "  # log 출력\n",
        "  print(\"Epoch: {:4d}/{}, Cost: {:.4f}\".format(\n",
        "      epoch+1, training_epochs, avg_cost\n",
        "  ))\n",
        "\n",
        "print(\"Learning Finished\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80SUPHkjW6xK",
        "outputId": "641bed6b-3e78-422c-d6c7-2692f874a453"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    1/15, Cost: 0.2769\n",
            "Epoch:    2/15, Cost: 0.2732\n",
            "Epoch:    3/15, Cost: 0.2700\n",
            "Epoch:    4/15, Cost: 0.2676\n",
            "Epoch:    5/15, Cost: 0.2644\n",
            "Epoch:    6/15, Cost: 0.2618\n",
            "Epoch:    7/15, Cost: 0.2593\n",
            "Epoch:    8/15, Cost: 0.2574\n",
            "Epoch:    9/15, Cost: 0.2550\n",
            "Epoch:   10/15, Cost: 0.2529\n",
            "Epoch:   11/15, Cost: 0.2507\n",
            "Epoch:   12/15, Cost: 0.2490\n",
            "Epoch:   13/15, Cost: 0.2470\n",
            "Epoch:   14/15, Cost: 0.2452\n",
            "Epoch:   15/15, Cost: 0.2439\n",
            "Learning Finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 결과 Test '''\n",
        "\n",
        "with torch.no_grad(): # gradient 계산 없이 빠르게 진행\n",
        "  \n",
        "  #1. 전체 test Data 이용 정확도 확인\n",
        "\n",
        "  X_test = mnist_test.test_data.view(-1,28*28).float().to(device)\n",
        "  Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "  prediction = linear(X_test) # nn.Linear\n",
        "  correct_prediction = (torch.argmax(prediction, 1) == Y_test )\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "  print(\"Accuracy: {:.4f}%\".format( accuracy.item()*100 ), end=\"\\n\\n\")\n",
        "\n",
        "  #2. 임의의 1개 data 이용, 예측값 확인해보기\n",
        "  r = random.randint(0, len(mnist_test) - 1)\n",
        "  X_single_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float().to(device)\n",
        "  Y_single_data = mnist_test.test_labels[r:r+1].to(device)\n",
        "\n",
        "  print(\"Label: \", Y_single_data.item())\n",
        "  single_prediction = linear(X_single_data)\n",
        "  print(\"Prediction: \", torch.argmax(single_prediction, 1).item())\n",
        "\n",
        "  plt.imshow(mnist_test.test_data[r:r+1].view(28,28),\n",
        "             cmap = \"Greys\", interpolation = \"nearest\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "j0ZBuE_OYV-U",
        "outputId": "212b2767-0b4e-4e4a-c0e7-9b0c45506fbf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.8400%\n",
            "\n",
            "Label:  9\n",
            "Prediction:  9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbrklEQVR4nO3df2xV9f3H8dflR6+g7a21tLcdbS0ooiI1MqmdijgaaJcYUbaJmg2MwcCKGXZO00VB3LLuixkzGoZmm3RuIs5EQF1k0WJL1BZHhTDjbCipA0JvmSTcW4otSD/fPwh3XinCudzbd295PpKT0Hvvu+fj8aZPDvf2XJ9zzgkAgAE2zHoBAIDzEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmRlgv4Ov6+vq0f/9+paeny+fzWS8HAOCRc05dXV3Kz8/XsGGnP88ZdAHav3+/CgoKrJcBADhHe/fu1dixY097/6ALUHp6uqQTC8/IyDBeDQDAq0gkooKCgujP89NJWoBWrVqlp556SqFQSCUlJXr22Wc1derUM86d/Ge3jIwMAgQAKexML6Mk5U0Ir7zyiqqrq7Vs2TJ99NFHKikp0axZs3TgwIFk7A4AkIKSEqCVK1dqwYIFuu+++3TVVVfpueee0+jRo/XCCy8kY3cAgBSU8AAdPXpULS0tKi8v/99Ohg1TeXm5mpqaTnl8b2+vIpFIzAYAGPoSHqDPP/9cx48fV25ubsztubm5CoVCpzy+trZWgUAguvEOOAA4P5j/ImpNTY3C4XB027t3r/WSAAADIOHvgsvOztbw4cPV2dkZc3tnZ6eCweApj/f7/fL7/YleBgBgkEv4GVBaWpqmTJmi+vr66G19fX2qr69XWVlZoncHAEhRSfk9oOrqas2bN0/f/va3NXXqVD399NPq7u7Wfffdl4zdAQBSUFICdNddd+m///2vli5dqlAopGuvvVabNm065Y0JAIDzl88556wX8VWRSESBQEDhcJgrIQBACjrbn+Pm74IDAJyfCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAiYQH6IknnpDP54vZJk6cmOjdAABS3IhkfNOrr75a77zzzv92MiIpuwEApLCklGHEiBEKBoPJ+NYAgCEiKa8B7dq1S/n5+Ro3bpzuvfde7dmz57SP7e3tVSQSidkAAENfwgNUWlqquro6bdq0SatXr1Z7e7tuvvlmdXV19fv42tpaBQKB6FZQUJDoJQEABiGfc84lcweHDh1SUVGRVq5cqfvvv/+U+3t7e9Xb2xv9OhKJqKCgQOFwWBkZGclcGgAgCSKRiAKBwBl/jif93QGZmZmaMGGC2tra+r3f7/fL7/cnexkAgEEm6b8HdPjwYe3evVt5eXnJ3hUAIIUkPEAPP/ywGhsb9dlnn+mDDz7QHXfcoeHDh+vuu+9O9K4AACks4f8Et2/fPt199906ePCgxowZo5tuuknNzc0aM2ZMoncFAEhhCQ/QunXrEv0tgUHt+PHjnme2bNnieeZHP/qR55l4fwl8ypQpnmcefPBBzzO33HKL5xmfz+d5BoMT14IDAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwk/RNRvTrbT9IDkmHXrl2eZyoqKjzPtLe3e56J5yKcWVlZnmck6YsvvvA8c+TIEc8z//znPz3PxHOhVAyss/05zhkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATIywXgCQDI2NjXHN/fjHP/Y8s3fvXs8z5eXlnmeWL1/ueaasrMzzjCQdOHDA88y1117reeaHP/yh55lPPvnE84zf7/c8g+TjDAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSDHoNTQ0eJ6prKyMa18XX3yx55m//vWvnmfuuecezzMDKScnx/PMCy+84HnmH//4h+eZ4cOHe57B4MQZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwuecc9aL+KpIJKJAIKBwOKyMjAzr5SDBWltbPc/cdNNNnmcmTJjgeUaS1q1b53mmoKAgrn0BQ9XZ/hznDAgAYIIAAQBMeA7Qli1bdNtttyk/P18+n08bNmyIud85p6VLlyovL0+jRo1SeXm5du3alaj1AgCGCM8B6u7uVklJiVatWtXv/StWrNAzzzyj5557Tlu3btWFF16oWbNmqaen55wXCwAYOjx/ImplZeVpP23SOaenn35ajz32mG6//XZJ0osvvqjc3Fxt2LBBc+fOPbfVAgCGjIS+BtTe3q5QKKTy8vLobYFAQKWlpWpqaup3pre3V5FIJGYDAAx9CQ1QKBSSJOXm5sbcnpubG73v62praxUIBKIbb2kFgPOD+bvgampqFA6Ho9vevXutlwQAGAAJDVAwGJQkdXZ2xtze2dkZve/r/H6/MjIyYjYAwNCX0AAVFxcrGAyqvr4+elskEtHWrVtVVlaWyF0BAFKc53fBHT58WG1tbdGv29vbtWPHDmVlZamwsFBLlizRr371K11++eUqLi7W448/rvz8fM2ePTuR6wYApDjPAdq2bZtuvfXW6NfV1dWSpHnz5qmurk6PPPKIuru79cADD+jQoUO66aabtGnTJl1wwQWJWzUAIOVxMVLE7fPPP/c8c/PNN3ue6ejo8DzT0tLieUaSxo8fH9fcULNv3z7PM1/9p/ezNXXqVM8zV155pecZDCwuRgoAGNQIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwvPHMQAn/eEPf/A809ra6nnmtdde8zzDVa1POH78eFxz3//+9z3PfPjhh55nxowZ43mmvb3d88zo0aM9zyD5OAMCAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwMVLok08+iWvu2Wef9Txzyy23eJ6prKz0PDMUdXV1eZ55/PHH49pXPBcWjcdVV13leYYLiw4dnAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GCm0ffv2uOZCoZDnmSeffNLzjN/v9zwzkHbu3Ol55sUXX/Q88/zzz3ue6e7u9jwzkKqrq62XAEOcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgYKQZUXV2d55l//etfnmcOHDjgeUaSXn/9dc8zPT09nmecc55nLr/8cs8zN9xwg+cZSfrLX/4S15xXpaWlA7IfDE6cAQEATBAgAIAJzwHasmWLbrvtNuXn58vn82nDhg0x98+fP18+ny9mq6ioSNR6AQBDhOcAdXd3q6SkRKtWrTrtYyoqKtTR0RHdXn755XNaJABg6PH8JoTKykpVVlZ+42P8fr+CwWDciwIADH1JeQ2ooaFBOTk5uuKKK7Ro0SIdPHjwtI/t7e1VJBKJ2QAAQ1/CA1RRUaEXX3xR9fX1+r//+z81NjaqsrJSx48f7/fxtbW1CgQC0a2goCDRSwIADEIJ/z2guXPnRv98zTXXaPLkyRo/frwaGho0Y8aMUx5fU1Oj6urq6NeRSIQIAcB5IOlvwx43bpyys7PV1tbW7/1+v18ZGRkxGwBg6Et6gPbt26eDBw8qLy8v2bsCAKQQz/8Ed/jw4Zizmfb2du3YsUNZWVnKysrS8uXLNWfOHAWDQe3evVuPPPKILrvsMs2aNSuhCwcApDbPAdq2bZtuvfXW6NcnX7+ZN2+eVq9erZ07d+rPf/6zDh06pPz8fM2cOVO//OUv5ff7E7dqAEDK87l4roqYRJFIRIFAQOFwmNeDBsgHH3wQ19z06dM9z3z55Zdx7curESPie39NcXGx55kFCxZ4nvnBD37geaaoqMjzTHNzs+cZSfrOd77jeSae9X366aeeZ/jL7OB3tj/HuRYcAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATCT8I7mReuK58rEkhUIhzzPPP/+855mvfvzH2bryyis9z0hSIBCIa26w+u1vfztg+5o7d67nGa5sfX7jDAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSBG3rKwszzM1NTVJWMn5wTnneaanpycJK+nfvffeO2D7wtDAGRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKLkQIporW11fPM3//+97j2VVhY6HlmwoQJce0L5y/OgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE1yMFEgRv/71rwdsXwsXLvQ8k5aWloSVYCjjDAgAYIIAAQBMeApQbW2trr/+eqWnpysnJ0ezZ88+5TNKenp6VFVVpUsuuUQXXXSR5syZo87OzoQuGgCQ+jwFqLGxUVVVVWpubtbbb7+tY8eOaebMmeru7o4+5qGHHtIbb7yhV199VY2Njdq/f7/uvPPOhC8cAJDaPL0JYdOmTTFf19XVKScnRy0tLZo2bZrC4bD+9Kc/ae3atfrud78rSVqzZo2uvPJKNTc364YbbkjcygEAKe2cXgMKh8OSpKysLElSS0uLjh07pvLy8uhjJk6cqMLCQjU1NfX7PXp7exWJRGI2AMDQF3eA+vr6tGTJEt14442aNGmSJCkUCiktLU2ZmZkxj83NzVUoFOr3+9TW1ioQCES3goKCeJcEAEghcQeoqqpKH3/8sdatW3dOC6ipqVE4HI5ue/fuPafvBwBIDXH9IurixYv15ptvasuWLRo7dmz09mAwqKNHj+rQoUMxZ0GdnZ0KBoP9fi+/3y+/3x/PMgAAKczTGZBzTosXL9b69eu1efNmFRcXx9w/ZcoUjRw5UvX19dHbWltbtWfPHpWVlSVmxQCAIcHTGVBVVZXWrl2rjRs3Kj09Pfq6TiAQ0KhRoxQIBHT//ferurpaWVlZysjI0IMPPqiysjLeAQcAiOEpQKtXr5YkTZ8+Peb2NWvWaP78+ZKk3/3udxo2bJjmzJmj3t5ezZo1S7///e8TslgAwNDhc84560V8VSQSUSAQUDgcVkZGhvVygKT48ssvPc9kZ2d7non31xra2to8z4wbNy6ufWHoOduf41wLDgBgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACbi+kRUAOfmj3/8o+eZeK5sfd1113mekaTCwsK45gAvOAMCAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwMVLAwFtvvTUg+xk5cmRcc11dXZ5nLr744rj2hfMXZ0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkuRgoYeP311z3P+Hw+zzPTpk3zPCNJgUAgrjnAC86AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATXIwUMFBUVOR5JjMz0/PM0qVLPc9I0rBh/N0UycezDABgggABAEx4ClBtba2uv/56paenKycnR7Nnz1Zra2vMY6ZPny6fzxezLVy4MKGLBgCkPk8BamxsVFVVlZqbm/X222/r2LFjmjlzprq7u2Met2DBAnV0dES3FStWJHTRAIDU5+lNCJs2bYr5uq6uTjk5OWppaYn55MXRo0crGAwmZoUAgCHpnF4DCofDkqSsrKyY21966SVlZ2dr0qRJqqmp0ZEjR077PXp7exWJRGI2AMDQF/fbsPv6+rRkyRLdeOONmjRpUvT2e+65R0VFRcrPz9fOnTv16KOPqrW1Va+99lq/36e2tlbLly+PdxkAgBTlc865eAYXLVqkt956S++9957Gjh172sdt3rxZM2bMUFtbm8aPH3/K/b29vert7Y1+HYlEVFBQoHA4rIyMjHiWBgx6l156qeeZeH4P6P333/c8I0kXXnhhXHOAdOLneCAQOOPP8bjOgBYvXqw333xTW7Zs+cb4SFJpaakknTZAfr9ffr8/nmUAAFKYpwA55/Tggw9q/fr1amhoUHFx8RlnduzYIUnKy8uLa4EAgKHJU4Cqqqq0du1abdy4Uenp6QqFQpKkQCCgUaNGaffu3Vq7dq2+973v6ZJLLtHOnTv10EMPadq0aZo8eXJS/gMAAKnJU4BWr14t6cQvm37VmjVrNH/+fKWlpemdd97R008/re7ubhUUFGjOnDl67LHHErZgAMDQ4Pmf4L5JQUGBGhsbz2lBAIDzA1fDBgx89tln1ksAzHExUgCACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEyMsF7A1znnJEmRSMR4JQCAeJz8+X3y5/npDLoAdXV1SZIKCgqMVwIAOBddXV0KBAKnvd/nzpSoAdbX16f9+/crPT1dPp8v5r5IJKKCggLt3btXGRkZRiu0x3E4geNwAsfhBI7DCYPhODjn1NXVpfz8fA0bdvpXegbdGdCwYcM0duzYb3xMRkbGef0EO4njcALH4QSOwwkchxOsj8M3nfmcxJsQAAAmCBAAwERKBcjv92vZsmXy+/3WSzHFcTiB43ACx+EEjsMJqXQcBt2bEAAA54eUOgMCAAwdBAgAYIIAAQBMECAAgImUCdCqVat06aWX6oILLlBpaak+/PBD6yUNuCeeeEI+ny9mmzhxovWykm7Lli267bbblJ+fL5/Ppw0bNsTc75zT0qVLlZeXp1GjRqm8vFy7du2yWWwSnek4zJ8//5TnR0VFhc1ik6S2tlbXX3+90tPTlZOTo9mzZ6u1tTXmMT09PaqqqtIll1yiiy66SHPmzFFnZ6fRipPjbI7D9OnTT3k+LFy40GjF/UuJAL3yyiuqrq7WsmXL9NFHH6mkpESzZs3SgQMHrJc24K6++mp1dHREt/fee896SUnX3d2tkpISrVq1qt/7V6xYoWeeeUbPPfectm7dqgsvvFCzZs1ST0/PAK80uc50HCSpoqIi5vnx8ssvD+AKk6+xsVFVVVVqbm7W22+/rWPHjmnmzJnq7u6OPuahhx7SG2+8oVdffVWNjY3av3+/7rzzTsNVJ97ZHAdJWrBgQczzYcWKFUYrPg2XAqZOneqqqqqiXx8/ftzl5+e72tpaw1UNvGXLlrmSkhLrZZiS5NavXx/9uq+vzwWDQffUU09Fbzt06JDz+/3u5ZdfNljhwPj6cXDOuXnz5rnbb7/dZD1WDhw44CS5xsZG59yJ//cjR450r776avQx//73v50k19TUZLXMpPv6cXDOuVtuucX99Kc/tVvUWRj0Z0BHjx5VS0uLysvLo7cNGzZM5eXlampqMlyZjV27dik/P1/jxo3Tvffeqz179lgvyVR7e7tCoVDM8yMQCKi0tPS8fH40NDQoJydHV1xxhRYtWqSDBw9aLympwuGwJCkrK0uS1NLSomPHjsU8HyZOnKjCwsIh/Xz4+nE46aWXXlJ2drYmTZqkmpoaHTlyxGJ5pzXoLkb6dZ9//rmOHz+u3NzcmNtzc3P16aefGq3KRmlpqerq6nTFFVeoo6NDy5cv180336yPP/5Y6enp1sszEQqFJKnf58fJ+84XFRUVuvPOO1VcXKzdu3frF7/4hSorK9XU1KThw4dbLy/h+vr6tGTJEt14442aNGmSpBPPh7S0NGVmZsY8dig/H/o7DpJ0zz33qKioSPn5+dq5c6ceffRRtba26rXXXjNcbaxBHyD8T2VlZfTPkydPVmlpqYqKivS3v/1N999/v+HKMBjMnTs3+udrrrlGkydP1vjx49XQ0KAZM2YYriw5qqqq9PHHH58Xr4N+k9MdhwceeCD652uuuUZ5eXmaMWOGdu/erfHjxw/0Mvs16P8JLjs7W8OHDz/lXSydnZ0KBoNGqxocMjMzNWHCBLW1tVkvxczJ5wDPj1ONGzdO2dnZQ/L5sXjxYr355pt69913Yz6+JRgM6ujRozp06FDM44fq8+F0x6E/paWlkjSong+DPkBpaWmaMmWK6uvro7f19fWpvr5eZWVlhiuzd/jwYe3evVt5eXnWSzFTXFysYDAY8/yIRCLaunXref/82Ldvnw4ePDiknh/OOS1evFjr16/X5s2bVVxcHHP/lClTNHLkyJjnQ2trq/bs2TOkng9nOg792bFjhyQNrueD9bsgzsa6deuc3+93dXV17pNPPnEPPPCAy8zMdKFQyHppA+pnP/uZa2hocO3t7e7999935eXlLjs72x04cMB6aUnV1dXltm/f7rZv3+4kuZUrV7rt27e7//znP845537zm9+4zMxMt3HjRrdz5053++23u+LiYvfFF18Yrzyxvuk4dHV1uYcfftg1NTW59vZ2984777jrrrvOXX755a6np8d66QmzaNEiFwgEXENDg+vo6IhuR44ciT5m4cKFrrCw0G3evNlt27bNlZWVubKyMsNVJ96ZjkNbW5t78skn3bZt21x7e7vbuHGjGzdunJs2bZrxymOlRICcc+7ZZ591hYWFLi0tzU2dOtU1NzdbL2nA3XXXXS4vL8+lpaW5b33rW+6uu+5ybW1t1stKunfffddJOmWbN2+ec+7EW7Eff/xxl5ub6/x+v5sxY4ZrbW21XXQSfNNxOHLkiJs5c6YbM2aMGzlypCsqKnILFiwYcn9J6++/X5Jbs2ZN9DFffPGF+8lPfuIuvvhiN3r0aHfHHXe4jo4Ou0UnwZmOw549e9y0adNcVlaW8/v97rLLLnM///nPXTgctl341/BxDAAAE4P+NSAAwNBEgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJj4fzy02YPBPQvVAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}