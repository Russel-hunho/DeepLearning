{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlQPuGF5wCT0YCx5XjVLEj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Russel-hunho/DeepLearning/blob/main/pytorch_Softmax_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://wikidocs.net/59425"
      ],
      "metadata": {
        "id": "vwNHwJa2bVp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**다중 클래스 분류**\n",
        "> 3개 이상의 선택지로부터 1개를 선택하는 문제\n",
        "\n",
        "**소프트맥스(Softmax Regression) 회귀**:\n",
        "> 다중 클래스 분류 문제를 풀기 위한 알고리즘 중 하나"
      ],
      "metadata": {
        "id": "RznIHcEpbZBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 원-핫 인코딩(One-hot Encoding)"
      ],
      "metadata": {
        "id": "l66sGu1LbXAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "원-핫 인코딩: 범주형 데이터의 레이블을 표현하는 방법\n",
        "\n",
        "* 선택하야 하는 선택지의 개수만큼의 차원을 가짐\n",
        "* 각 선택지의 인덱스에 해당하는 원소는 1, 나머지는 0 값을 부여\n",
        "> ex) 3개 선택지: A = [1,0,0]. B = [0,1,0], C = [0,0,1]\n",
        "* 이때, 값을 부여한 벡터 (A,B,C)들을 **원-핫 벡터(one-hot vector)** 라고 한다!\n",
        "* 장점(필요성): **\"관계의 무작위성\" 부여**"
      ],
      "metadata": {
        "id": "uoETDepJcKNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 소프트맥스 회귀 이해\n",
        "다중 클래스 분류(Multi-class Classification)"
      ],
      "metadata": {
        "id": "0AVCYeyIdSrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "X -> Z -> P(예측 벡터) -> Y(결과값, 원-핫 벡터 형식)\n",
        "\n",
        "* [Step1] 입력 X = [x1,x2,...]를, Softmax함수의 입력 Z로 바꾼다!\n",
        "> Z: 답(Y)와 크기가 동일해야함!\n",
        "\n",
        "* [Step2] input Z를 softmax 함수를 적용하여 P 구하기\n",
        "> P: 각 답이 나올 확률벡터; 원소의 총 합 = 1\n",
        "\n",
        "* [step3] P ~ Y간 오차 계산을 통한, softmax 가중치 수정\n",
        "> 적절한 Cost Function: **크로스 엔트로피 함수** 사용!\n",
        ">> cost(W) = - Σ[ (yᵢ)*log(pᵢ) ]\n",
        ">>> 로지스틱(이진분류)에선, y1 = y, y2 = (1-y) 였던 것\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XMvUFfudeErs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.소프트맥스 회귀 비용함수 구현"
      ],
      "metadata": {
        "id": "xmJxHWcnhHM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1. 로우레벨 구현:\n",
        "* F.Softmax 함수 이용 Softmax 적용\n",
        "* torch.log 함수 이용 Cost Function 계산"
      ],
      "metadata": {
        "id": "YxiFKN66petA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "B3_wNiJOcJ9y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.FloatTensor([1,2,3])"
      ],
      "metadata": {
        "id": "pGnZK2qJbU1A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "hypothesis = F.softmax(z, dim = 0) # 첫번째 차원에 소프트맥스 함수를 적용한다는 의미)\n",
        "print(hypothesis) # P 벡터\n",
        "print(hypothesis.sum()) # 합은 1이다!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fTyHWhwhWHv",
        "outputId": "eca36b21-dc98-43ac-ca49-cc34b2252d96"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3412, 0.2938, 0.2671, 0.4002, 0.2469],\n",
            "        [0.3559, 0.3306, 0.3796, 0.3393, 0.3719],\n",
            "        [0.3029, 0.3756, 0.3533, 0.2605, 0.3812]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(5., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 연습 data '''\n",
        "\n",
        "torch.manual_seed(1)\n",
        "z = torch.rand(3,5,requires_grad = True) # 3x5 크기의 input, 0~1 사이 random 값\n",
        "print(z)\n",
        "print()\n",
        "\n",
        "''' P값 계산 w/ softmax 함수 '''\n",
        "\n",
        "hypothesis = F.softmax(z, dim = 1)\n",
        "  # 두번째 차원에 소프트맥스 함수 적용)\n",
        "  # 각 샘플(5개 data)에 대해 적용\n",
        "print(hypothesis)\n",
        "\n",
        "for i in range(3):\n",
        "  print(hypothesis[i].sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kiY8W87mT7O",
        "outputId": "7f25b110-1775-4f85-ed72-ade55c46a08d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7576, 0.2793, 0.4031, 0.7347, 0.0293],\n",
            "        [0.7999, 0.3971, 0.7544, 0.5695, 0.4388],\n",
            "        [0.6387, 0.5247, 0.6826, 0.3051, 0.4635]], requires_grad=True)\n",
            "\n",
            "tensor([[0.2645, 0.1639, 0.1855, 0.2585, 0.1277],\n",
            "        [0.2430, 0.1624, 0.2322, 0.1930, 0.1694],\n",
            "        [0.2226, 0.1986, 0.2326, 0.1594, 0.1868]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "y = torch.randint(5, (3,)).long()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh5IL7DundKQ",
        "outputId": "11b85c9e-9d5d-412b-9498-9c8bf21ef8d7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 원-핫 인코딩 '''\n",
        "y_one_hot = torch.zeros_like(hypothesis)\n",
        "y_one_hot.scatter_(1, y.unsqueeze(1),1)\n",
        "  # dim = 1 에서 / y.unsqueeze(1)의 원소에 해당하는 위치에 / 1을 넣어라\n",
        "\n",
        "# y의 dim 확장\n",
        "print(y.unsqueeze(1), end=\"\\n\\n\")\n",
        "\n",
        "print(y_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNlAueBn3wY",
        "outputId": "ba109228-ecef-4906-dfd0-9e13fc58d424"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0],\n",
            "        [4],\n",
            "        [4]])\n",
            "\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' cost function 계산 '''\n",
        "\n",
        "cost = (-1) * (y_one_hot * torch.log(hypothesis)).sum(dim = 1).mean()\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5D2d7ruo8qs",
        "outputId": "a85a1549-fa00-4d7f-9fa9-3a34de7c0256"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5945, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2. 하이레벨 구현\n",
        "* **F.log_softmax()**: F.softmax() 와 torch.log()를 결합하여, 한번에 계산!\n",
        "* **F.nll_loss()**: F.log_softmax()를 인자로 받아, cost function 계산 식을 한번에 구현!\n",
        "> NLL: Negative Log Likelihood\n",
        "* **F.cross_entropy()**: F.nll_loss()와 F.log_softmax()를 결합하여, 한번에 계산!"
      ],
      "metadata": {
        "id": "JSC1w05RhXG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연습 data\n",
        "z = torch.rand(3,5,requires_grad = True) # 3x5 크기의 input, 0~1 사이 random 값\n",
        "y = torch.randint(5, (3,)).long()\n",
        "y_one_hot = torch.zeros_like(hypothesis)\n",
        "y_one_hot.scatter_(1, y.unsqueeze(1),1)\n",
        "\n",
        "# Low Level 방식\n",
        "print( torch.log(F.softmax(z,dim = 1)) )\n",
        "cost = (-1)*( y_one_hot * torch.log(F.softmax(z,dim=1)) ).sum(dim=1).mean()\n",
        "print(cost , end = \"\\n\\n\")\n",
        "''' = \n",
        "hypothesis = F.softmax(z,dim = 1)\n",
        "cost = (-1) * ( y_one_hot * torch.log(hypothesis) ).sum(dim=1).mean()\n",
        "'''\n",
        "\n",
        "# torch.log와 torch.softmax를 한번에 계산\n",
        "print( torch.log_softmax(z,dim=1) )\n",
        "cost = (-1)*( y_one_hot * F.log_softmax(z,dim=1) ).sum(dim=1).mean()\n",
        "print(cost , end = \"\\n\\n\")\n",
        "\n",
        "# Cost 계산식을 F.nll_loss로 계산\n",
        "cost = F.nll_loss( F.log_softmax(z,dim=1), y)\n",
        "print(cost , end = \"\\n\\n\")\n",
        "\n",
        "# High Level 방식\n",
        "# cross_entropy로 cost를 한번에 계산\n",
        "cost = F.cross_entropy(z,y)\n",
        "print(cost , end = \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZebpuXPupih6",
        "outputId": "f5e1a794-53fb-473d-f00b-1a06dc09c235"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.0104, -1.3722, -1.5215, -1.9999, -1.3519],\n",
            "        [-1.4156, -1.2757, -1.9994, -1.8014, -1.7288],\n",
            "        [-1.4667, -1.9192, -1.8945, -1.2677, -1.6570]], grad_fn=<LogBackward0>)\n",
            "tensor(1.9681, grad_fn=<MulBackward0>)\n",
            "\n",
            "tensor([[-2.0104, -1.3722, -1.5215, -1.9999, -1.3519],\n",
            "        [-1.4156, -1.2757, -1.9994, -1.8014, -1.7288],\n",
            "        [-1.4667, -1.9192, -1.8945, -1.2677, -1.6570]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor(1.9681, grad_fn=<MulBackward0>)\n",
            "\n",
            "tensor(1.9681, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "tensor(1.9681, grad_fn=<NllLossBackward0>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 소프트맥스 회귀 구현"
      ],
      "metadata": {
        "id": "I2PeOKLmurHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 공통 전처리\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#시드 고정\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# 훈련 데이터 설정\n",
        "x_train = [[1, 2, 1, 1],\n",
        "           [2, 1, 3, 2],\n",
        "           [3, 1, 3, 4],\n",
        "           [4, 1, 5, 5],\n",
        "           [1, 7, 5, 5],\n",
        "           [1, 2, 5, 6],\n",
        "           [1, 6, 6, 6],\n",
        "           [1, 7, 7, 7]]\n",
        "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "\n",
        "\n",
        "# y_one_hot 구현\n",
        "'''\n",
        "y는 8개의 data이지만, 범주로는 [0,1,2] 3개의 data를 갖는다\n",
        "-> X(8x4) -> Y_one-hot(8x3) -> Y(8)\n",
        "'''\n",
        "y_one_hot = torch.zeros(8,3)\n",
        "y_one_hot.scatter_(1,y_train.unsqueeze(1),1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVVVc2ojuthe",
        "outputId": "558e8fcb-e02a-4978-c4af-d4ab4d3a2c37"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1.],\n",
              "        [0., 0., 1.],\n",
              "        [0., 0., 1.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [1., 0., 0.],\n",
              "        [1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1. 로우레벨 모델 구현\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vmon4653vfkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 para 설정\n",
        "W = torch.zeros((4,3), requires_grad = True)\n",
        "b = torch.zeros((1,3), requires_grad = True)\n",
        "\n",
        "# Optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr = 0.01)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(X) = softmax( WX + B )\n",
        "  hypothesis = F.softmax( x_train.matmul(W) + b, dim = 1 )\n",
        "\n",
        "  # cost\n",
        "  cost = (-1) * ( y_one_hot * hypothesis ).sum(dim=1).mean()\n",
        "\n",
        "  # 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 로그 출력\n",
        "  if epoch%100 == 0:\n",
        "    print(\"Epoch: {:4d}/{}, Cost: {:.6f}\".format(\n",
        "        epoch, nb_epochs, cost.item()\n",
        "    ), end = \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ivN-8mvajH",
        "outputId": "17b0ca3d-2d29-43a0-ec7f-1018277c7304"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    0/1000, Cost: -0.333333\n",
            "Epoch:  100/1000, Cost: -0.412802\n",
            "Epoch:  200/1000, Cost: -0.457824\n",
            "Epoch:  300/1000, Cost: -0.491296\n",
            "Epoch:  400/1000, Cost: -0.517861\n",
            "Epoch:  500/1000, Cost: -0.540541\n",
            "Epoch:  600/1000, Cost: -0.560789\n",
            "Epoch:  700/1000, Cost: -0.579231\n",
            "Epoch:  800/1000, Cost: -0.596110\n",
            "Epoch:  900/1000, Cost: -0.611523\n",
            "Epoch: 1000/1000, Cost: -0.625530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2. 하이레벨 구현"
      ],
      "metadata": {
        "id": "d_umg-Sbvigb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model 설정\n",
        "W = torch.zeros((4,3), requires_grad = True)\n",
        "b = torch.zeros((1,3), requires_grad = True)\n",
        "\n",
        "# Optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr = 0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  \n",
        "  # Z 구현\n",
        "  z = x_train.matmul(W)+b\n",
        "  \n",
        "  # Cost 계산\n",
        "  cost = F.cross_entropy(z, y_train)\n",
        "\n",
        "  # 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 100번마다 로그 출력\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfsDup3mvljG",
        "outputId": "0a78a10a-3f55-43c2-9266-35debef0208e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.098612\n",
            "Epoch  100/1000 Cost: 0.704199\n",
            "Epoch  200/1000 Cost: 0.623000\n",
            "Epoch  300/1000 Cost: 0.565717\n",
            "Epoch  400/1000 Cost: 0.515291\n",
            "Epoch  500/1000 Cost: 0.467662\n",
            "Epoch  600/1000 Cost: 0.421278\n",
            "Epoch  700/1000 Cost: 0.375402\n",
            "Epoch  800/1000 Cost: 0.329766\n",
            "Epoch  900/1000 Cost: 0.285073\n",
            "Epoch 1000/1000 Cost: 0.248155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.3. nn.Module로 구현"
      ],
      "metadata": {
        "id": "0Xl7pXxvB-IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(4,3)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(X)\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  # Cost\n",
        "  cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "  #개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 20번마다 로그 출력\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GszbD3vB932",
        "outputId": "17549a61-c542-4b5a-ee06-1b172484c41b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.616785\n",
            "Epoch  100/1000 Cost: 0.658891\n",
            "Epoch  200/1000 Cost: 0.573443\n",
            "Epoch  300/1000 Cost: 0.518151\n",
            "Epoch  400/1000 Cost: 0.473265\n",
            "Epoch  500/1000 Cost: 0.433516\n",
            "Epoch  600/1000 Cost: 0.396563\n",
            "Epoch  700/1000 Cost: 0.360914\n",
            "Epoch  800/1000 Cost: 0.325392\n",
            "Epoch  900/1000 Cost: 0.289178\n",
            "Epoch 1000/1000 Cost: 0.254148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.4. Class로 구현"
      ],
      "metadata": {
        "id": "BFP6M1D-CiXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(4,3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "metadata": {
        "id": "u8zJDCntChvD"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  \n",
        "  #H(X)\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  #Cost\n",
        "  cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "  #개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # log 출력\n",
        "  if epoch%100 == 0:\n",
        "    print(\"Epoch: {:4d}/{}, Cost: {:.4f}\".format(\n",
        "        epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyQigH4xC2Un",
        "outputId": "e7b94348-8f4d-4e45-c64b-0a5e572e9b66"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    0/1000, Cost: 3.7633\n",
            "Epoch:  100/1000, Cost: 0.6345\n",
            "Epoch:  200/1000, Cost: 0.5531\n",
            "Epoch:  300/1000, Cost: 0.4991\n",
            "Epoch:  400/1000, Cost: 0.4548\n",
            "Epoch:  500/1000, Cost: 0.4153\n",
            "Epoch:  600/1000, Cost: 0.3781\n",
            "Epoch:  700/1000, Cost: 0.3418\n",
            "Epoch:  800/1000, Cost: 0.3053\n",
            "Epoch:  900/1000, Cost: 0.2687\n",
            "Epoch: 1000/1000, Cost: 0.2428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Softmax 회귀로 MNIST 데이터 분류하기"
      ],
      "metadata": {
        "id": "ER-SvgNFEeSX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "utJwC9P1Ejvt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}