{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0RIF/y0+bkPTN9SAdxfVD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Russel-hunho/DeepLearning/blob/main/pytorch_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://wikidocs.net/53545"
      ],
      "metadata": {
        "id": "GSpEfzvQ5hst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. 선형 회귀(Linear Regression)"
      ],
      "metadata": {
        "id": "jvG3ezJk07Ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 가설(Hypothesis) 수립: y = H(x)\n",
        "      \n",
        "      선형회귀에선, H(x) = Wx+b\n",
        "      (W: 가중치, b: 편향(Bias))\n",
        "2. 비용함수(Cost Function) 설정 -> 최소화 하기\n",
        "3. 최적화 알고리즘 선택\n",
        "4. 손실 계산(Compute Loss)"
      ],
      "metadata": {
        "id": "REHv6vAi_z2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "비용 함수(cost function) = 손실 함수(loss function) = 오차 함수(error function) = 목적 함수(objective function)"
      ],
      "metadata": {
        "id": "nvK-12pv-uWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "옵티마이저(Optimizer) 알고리즘 = 최적화 알고리즘\n",
        "\n",
        "*   경사 하강법(Gradient Descent)\n",
        "*   항목 추가\n",
        "\n"
      ],
      "metadata": {
        "id": "bvQJ0f23-8b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 경사 하강법(Gradient Descent)\n",
        "가설: y = H(x) = Wx\n"
      ],
      "metadata": {
        "id": "wk_KgvK2_EhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "acpbmJKB_TCA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 항상 같은 결과가 나오도록 seed값 고정시키기\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDgoAnKSld6s",
        "outputId": "7230fc02-ab78-4e9c-f529-f5d5c7bb266a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc10c168bf0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rxWXEJGY0wGg"
      },
      "outputs": [],
      "source": [
        "''' [y = Wx + b] model을 학습시킬 data 설정 ''' \n",
        "\n",
        "# 변수 선언\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 가설에 사용할 가중치, 편향값의 초기값 설정'''\n",
        "\n",
        "# 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시함.\n",
        "W = torch.zeros(1, requires_grad=True) \n",
        "# 가중치 W를 출력\n",
        "print(W)\n",
        "\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "print(b)\n",
        "\n",
        "# 현재 H(x) = 0*x + 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wctSC93AlqPN",
        "outputId": "fedc7ac1-6e8d-4fc1-8abf-26b3e5351b54"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n",
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 가설 세우기 '''\n",
        "\n",
        "hypothesis = x_train * W + b\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz5uxh8Il_Gc",
        "outputId": "895e7250-6c9a-4ed2-892c-cc716f5194f1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 비용함수 선언 '''\n",
        "\n",
        "# 이번 선형회귀에선, 오차의 평균제곱으로 설정\n",
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ506v73mUnC",
        "outputId": "1c452333-7366-4449-cabd-5fe3fd1f52af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 경사하강법 구현 '''\n",
        "## SGD: 경사 하강법의 일종\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "  # lr: 학습률(Learning Rate)\n",
        "print(optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEkkxLmgmsYJ",
        "outputId": "26ddbe92-7008-4540-a062-f5af4482d6a7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient를 0으로 초기화\n",
        "optimizer.zero_grad()\n",
        "print(optimizer)\n",
        "# 비용 함수를 미분하여 gradient 계산\n",
        "cost.backward()\n",
        "print(cost)\n",
        "# W와 b를 업데이트\n",
        "optimizer.step()\n",
        "print(optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dIMHbrXm__X",
        "outputId": "9f27b4b8-af02-4ba8-ec01-496d924b1227"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 실행 코드"
      ],
      "metadata": {
        "id": "rZFusQakoDlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "## 항상 같은 결과가 나오도록 seed값 고정시키기\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "nb_epochs = 3500 # 원하는만큼 경사 하강법을 반복\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = x_train * W + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_45jDoBZoE6L",
        "outputId": "8862b743-2e09-4f76-efd3-36a418d7bc22"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/3500 W: 0.187, b: 0.080 Cost: 18.666666\n",
            "Epoch  100/3500 W: 1.746, b: 0.578 Cost: 0.048171\n",
            "Epoch  200/3500 W: 1.800, b: 0.454 Cost: 0.029767\n",
            "Epoch  300/3500 W: 1.843, b: 0.357 Cost: 0.018394\n",
            "Epoch  400/3500 W: 1.876, b: 0.281 Cost: 0.011366\n",
            "Epoch  500/3500 W: 1.903, b: 0.221 Cost: 0.007024\n",
            "Epoch  600/3500 W: 1.924, b: 0.174 Cost: 0.004340\n",
            "Epoch  700/3500 W: 1.940, b: 0.136 Cost: 0.002682\n",
            "Epoch  800/3500 W: 1.953, b: 0.107 Cost: 0.001657\n",
            "Epoch  900/3500 W: 1.963, b: 0.084 Cost: 0.001024\n",
            "Epoch 1000/3500 W: 1.971, b: 0.066 Cost: 0.000633\n",
            "Epoch 1100/3500 W: 1.977, b: 0.052 Cost: 0.000391\n",
            "Epoch 1200/3500 W: 1.982, b: 0.041 Cost: 0.000242\n",
            "Epoch 1300/3500 W: 1.986, b: 0.032 Cost: 0.000149\n",
            "Epoch 1400/3500 W: 1.989, b: 0.025 Cost: 0.000092\n",
            "Epoch 1500/3500 W: 1.991, b: 0.020 Cost: 0.000057\n",
            "Epoch 1600/3500 W: 1.993, b: 0.016 Cost: 0.000035\n",
            "Epoch 1700/3500 W: 1.995, b: 0.012 Cost: 0.000022\n",
            "Epoch 1800/3500 W: 1.996, b: 0.010 Cost: 0.000013\n",
            "Epoch 1900/3500 W: 1.997, b: 0.008 Cost: 0.000008\n",
            "Epoch 2000/3500 W: 1.997, b: 0.006 Cost: 0.000005\n",
            "Epoch 2100/3500 W: 1.998, b: 0.005 Cost: 0.000003\n",
            "Epoch 2200/3500 W: 1.998, b: 0.004 Cost: 0.000002\n",
            "Epoch 2300/3500 W: 1.999, b: 0.003 Cost: 0.000001\n",
            "Epoch 2400/3500 W: 1.999, b: 0.002 Cost: 0.000001\n",
            "Epoch 2500/3500 W: 1.999, b: 0.002 Cost: 0.000000\n",
            "Epoch 2600/3500 W: 1.999, b: 0.001 Cost: 0.000000\n",
            "Epoch 2700/3500 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 2800/3500 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 2900/3500 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 3000/3500 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 3100/3500 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3200/3500 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3300/3500 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3400/3500 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3500/3500 W: 2.000, b: 0.000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. 자동 미분(Autograd)"
      ],
      "metadata": {
        "id": "_fIKgxSopAlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치는 자동 미분(Autograd) 기능을 제공한다!"
      ],
      "metadata": {
        "id": "vgyMZ6IbxA8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "w = torch.tensor(2.0, requires_grad = True) # 스칼라 tensor\n",
        "  # requires_grad = True: 이 텐서에 대한 기울기를 저장하겠다!\n",
        "    # w.grad에, w에 대한 미분값이 저장된다.\n",
        "\n",
        "# 수식 정의\n",
        "y = w**2\n",
        "z = 2*y + 5\n",
        "\n",
        "# z의 w에 대한 기울기 계산\n",
        "z.backward()\n",
        "  # 결과는 w.grad에 저장된다!\n",
        "  # z를 w로 편미분한 후, w=2.0 값을 대입함\n",
        "print(\"수식을 w로 미분한 값: {}\".format(w.grad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS4Iot1Aw9az",
        "outputId": "c70536c5-94b9-432f-8b3f-c8a7369c925f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수식을 w로 미분한 값: 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 다중 선형 회귀(Multivariable Linear Regression)"
      ],
      "metadata": {
        "id": "oIoyJRsoyh46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다수의 x로부터 y를 예측하자"
      ],
      "metadata": {
        "id": "I1Ch9w_uyn17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H(x) = w1*x1 + w2*x2 + w3*x3 + b\n"
      ],
      "metadata": {
        "id": "nuSb32Yuy5GP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. 스칼라형 다변수 x1,x2,x3에 대한 다중 선형 회귀로 풀기"
      ],
      "metadata": {
        "id": "WY4cy9uN2GK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed((1)) # seed 고정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPobXTOhynNa",
        "outputId": "0e1f1c5f-3798-4715-e2af-80fa126822b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7d955d8bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 Data\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "HinqOGsRzix-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 w와 편향 b 초기화\n",
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)"
      ],
      "metadata": {
        "id": "ZZzvmN4ayhjR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5) # SGD모델, 학습률 = 1e-5\n",
        "\n",
        "nb_epochs = 1000 # 반복횟수\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  # H(X) 계산\n",
        "  hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
        "\n",
        "  # cost 계산 (에러 제곱 평균)\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward() # w1, w2, w3, b로 각각 편미분\n",
        "  optimizer.step()\n",
        "\n",
        "  # 100번마다 로그 출력\n",
        "  if epoch % 100 == 0:\n",
        "    print(\"Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}\".format(\n",
        "        epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
        "    ))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aZfEqzozui-",
        "outputId": "c88e6dfd-4225-456f-f8c9-fa9d4a0738b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 w1: 0.757 w2: 0.571 w3: 0.682 b: 0.011 Cost: 0.753650\n",
            "Epoch  100/1000 w1: 0.761 w2: 0.568 w3: 0.682 b: 0.011 Cost: 0.729680\n",
            "Epoch  200/1000 w1: 0.764 w2: 0.564 w3: 0.682 b: 0.011 Cost: 0.706930\n",
            "Epoch  300/1000 w1: 0.767 w2: 0.561 w3: 0.682 b: 0.011 Cost: 0.685357\n",
            "Epoch  400/1000 w1: 0.770 w2: 0.558 w3: 0.682 b: 0.011 Cost: 0.664896\n",
            "Epoch  500/1000 w1: 0.773 w2: 0.555 w3: 0.682 b: 0.011 Cost: 0.645467\n",
            "Epoch  600/1000 w1: 0.776 w2: 0.552 w3: 0.682 b: 0.011 Cost: 0.627032\n",
            "Epoch  700/1000 w1: 0.779 w2: 0.549 w3: 0.682 b: 0.012 Cost: 0.609540\n",
            "Epoch  800/1000 w1: 0.782 w2: 0.546 w3: 0.682 b: 0.012 Cost: 0.592941\n",
            "Epoch  900/1000 w1: 0.785 w2: 0.543 w3: 0.682 b: 0.012 Cost: 0.577177\n",
            "Epoch 1000/1000 w1: 0.788 w2: 0.540 w3: 0.682 b: 0.012 Cost: 0.562214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. 행렬 변수 X에 대한 선형 회귀로 풀기"
      ],
      "metadata": {
        "id": "OU1XjcIr2QL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H(X) = W*X + B\n",
        "\n",
        "W = [W1,W2,W3]\n",
        "\n",
        "X = [[x11, x12, x13], [x21, x22, x23],[x31, x32, x33]]\n",
        "\n",
        "B = [b b b]"
      ],
      "metadata": {
        "id": "1wqslui12WDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 Data\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  80], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "metadata": {
        "id": "MTYCIcKy2Vd0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치와 편향 선언\n",
        "W = torch.zeros((3,1), requires_grad = True)\n",
        "b = torch.zeros(1, requires_grad = True)"
      ],
      "metadata": {
        "id": "Dw65YC-R1T4f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr = 1e-5)\n",
        "\n",
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  hypothesis = x_train.matmul(W)+b\n",
        "\n",
        "  # cost 계산\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad() # gradient를 0으로 초기화\n",
        "  cost.backward() # 미분\n",
        "  optimizer.step()\n",
        "\n",
        "  #10번마다 출력\n",
        "  if epoch % 10 == 0: \n",
        "    print(\"Epoch {:4d}/{} hypothesis: {} Cost: {:6f}\".format(\n",
        "        epoch, nb_epochs, hypothesis, cost\n",
        "    ))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih-mcw8a3odi",
        "outputId": "2f82f5af-3bc5-4933-c421-a5cdc9069e72"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/100 hypothesis: tensor([[154.0430],\n",
            "        [185.0920],\n",
            "        [175.8333],\n",
            "        [198.5690],\n",
            "        [141.2222]], grad_fn=<AddBackward0>) Cost: 5.749629\n",
            "Epoch   10/100 hypothesis: tensor([[154.0415],\n",
            "        [185.0892],\n",
            "        [175.8437],\n",
            "        [198.5632],\n",
            "        [141.2229]], grad_fn=<AddBackward0>) Cost: 5.724895\n",
            "Epoch   20/100 hypothesis: tensor([[154.0399],\n",
            "        [185.0863],\n",
            "        [175.8540],\n",
            "        [198.5574],\n",
            "        [141.2235]], grad_fn=<AddBackward0>) Cost: 5.700261\n",
            "Epoch   30/100 hypothesis: tensor([[154.0384],\n",
            "        [185.0836],\n",
            "        [175.8643],\n",
            "        [198.5517],\n",
            "        [141.2241]], grad_fn=<AddBackward0>) Cost: 5.675793\n",
            "Epoch   40/100 hypothesis: tensor([[154.0368],\n",
            "        [185.0808],\n",
            "        [175.8746],\n",
            "        [198.5459],\n",
            "        [141.2247]], grad_fn=<AddBackward0>) Cost: 5.651419\n",
            "Epoch   50/100 hypothesis: tensor([[154.0353],\n",
            "        [185.0780],\n",
            "        [175.8848],\n",
            "        [198.5402],\n",
            "        [141.2253]], grad_fn=<AddBackward0>) Cost: 5.627147\n",
            "Epoch   60/100 hypothesis: tensor([[154.0337],\n",
            "        [185.0753],\n",
            "        [175.8950],\n",
            "        [198.5344],\n",
            "        [141.2260]], grad_fn=<AddBackward0>) Cost: 5.603012\n",
            "Epoch   70/100 hypothesis: tensor([[154.0322],\n",
            "        [185.0725],\n",
            "        [175.9052],\n",
            "        [198.5287],\n",
            "        [141.2266]], grad_fn=<AddBackward0>) Cost: 5.579025\n",
            "Epoch   80/100 hypothesis: tensor([[154.0306],\n",
            "        [185.0698],\n",
            "        [175.9153],\n",
            "        [198.5231],\n",
            "        [141.2272]], grad_fn=<AddBackward0>) Cost: 5.555122\n",
            "Epoch   90/100 hypothesis: tensor([[154.0291],\n",
            "        [185.0671],\n",
            "        [175.9255],\n",
            "        [198.5174],\n",
            "        [141.2279]], grad_fn=<AddBackward0>) Cost: 5.531332\n",
            "Epoch  100/100 hypothesis: tensor([[154.0275],\n",
            "        [185.0643],\n",
            "        [175.9356],\n",
            "        [198.5117],\n",
            "        [141.2286]], grad_fn=<AddBackward0>) Cost: 5.507647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. nn.Module로 선형 회귀 구현"
      ],
      "metadata": {
        "id": "GFKA537w5Rbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Module을 통해 더 쉽게 선형 회귀를 구현할 수 있다!"
      ],
      "metadata": {
        "id": "eMZ3gPSC5Wwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. nn.Linear() 로 선형 회귀 모델 구현\n",
        "\n",
        "         model = nn.Linear(input_dim, output_dim)\n",
        "2. nn.functional.mse_loss()로 평균제곱오차 구현\n",
        "\n",
        "         Cost = F.mse_loss(prediction, y_train)"
      ],
      "metadata": {
        "id": "jGobYslc7IOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. nn.Module로 단순선형회귀 구현"
      ],
      "metadata": {
        "id": "44gsoyyV-Y87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU2X_cJb5VHM",
        "outputId": "236f83f1-645a-4acb-9771-dfaad9d9e0fb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7d955d8bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ],
      "metadata": {
        "id": "WbII9_hx7rYa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 선언\n",
        "# model = nn.Linear(input_dim, output_dim)\n",
        "  # input_dim: 입력 차원, x의 개수\n",
        "  # output_dim: 출력 차원, y의 개수\n",
        "\n",
        "# 단순 선형 회귀 이므로, input_dim = 1; output_dim = 1;\n",
        "torch.manual_seed(1)\n",
        "model = nn.Linear(1,1)\n",
        "print(list(model.parameters()))\n",
        "  # W, b가 순서대로 출력된다\n",
        "  # 현재 print되어 나오는 값은 랜덤값! (seed 고정)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nml0dhW57tKc",
        "outputId": "bd85d395-1faa-4102-9fb0-e396da1e4413"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oprimizer 설정; SGD 사용\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "FUvNjq6v8gQG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  # cost 계산\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "    # torch.nn.functional에 있는 내장함수; 오차제곱평균(mse: mean square Error)\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad() # 미분값 초기화\n",
        "  cost.backward() # 미분값 계산\n",
        "  optimizer.step() # w,b 업데이트\n",
        "\n",
        "  #100번마다 출력\n",
        "  if epoch%100 == 0:\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk4zTGA477C4",
        "outputId": "21743ab7-51b7-4702-99ef-0a16e63fc616"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 완료된 model의 결과 data 확인\n",
        "\n",
        "# x = 4.0\n",
        "new_var = torch.FloatTensor([[4.0]])\n",
        "\n",
        "pred_y = model(new_var) # forward 연산\n",
        "print(\"훈련 후 입력이 4일 때의 예측 값: \", pred_y, end=\"\\n\\n\")\n",
        "\n",
        "# y = 2*x로, 8이 나와야 함!\n",
        "# 7.9989 -> 잘 근접함!\n",
        "\n",
        "# W,b 값 출력\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ynCjl_-9sp-",
        "outputId": "6b78a2fc-65e1-44d3-a223-e740fea17c90"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 4일 때의 예측 값:  tensor([[7.9989]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. nn.Module로 다중선형회귀 구현"
      ],
      "metadata": {
        "id": "8doT1PdC-e-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "# x1,x2,x3 -> y"
      ],
      "metadata": {
        "id": "2HIObDTpAJ2G"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model 선언\n",
        "torch.manual_seed(1)\n",
        "model = nn.Linear(3,1) # x 3개, y 1개\n",
        "\n",
        "print(list(model.parameters()))\n",
        "  # w1,w2,w3,b 출력됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AghvUhtm-g3Q",
        "outputId": "202b3c86-e167-4945-c372-ae990a17cd3e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2710], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(x)\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  # Cose\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "  # cost로 H 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  #100번마다 로그 출력\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9SpuKUxAbU2",
        "outputId": "8984a522-02f6-409d-c92f-23b527af3d2f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 31667.597656\n",
            "Epoch  100/2000 Cost: 0.225993\n",
            "Epoch  200/2000 Cost: 0.223911\n",
            "Epoch  300/2000 Cost: 0.221941\n",
            "Epoch  400/2000 Cost: 0.220059\n",
            "Epoch  500/2000 Cost: 0.218271\n",
            "Epoch  600/2000 Cost: 0.216575\n",
            "Epoch  700/2000 Cost: 0.214950\n",
            "Epoch  800/2000 Cost: 0.213413\n",
            "Epoch  900/2000 Cost: 0.211952\n",
            "Epoch 1000/2000 Cost: 0.210560\n",
            "Epoch 1100/2000 Cost: 0.209232\n",
            "Epoch 1200/2000 Cost: 0.207967\n",
            "Epoch 1300/2000 Cost: 0.206761\n",
            "Epoch 1400/2000 Cost: 0.205619\n",
            "Epoch 1500/2000 Cost: 0.204522\n",
            "Epoch 1600/2000 Cost: 0.203484\n",
            "Epoch 1700/2000 Cost: 0.202485\n",
            "Epoch 1800/2000 Cost: 0.201542\n",
            "Epoch 1900/2000 Cost: 0.200635\n",
            "Epoch 2000/2000 Cost: 0.199769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 결과 확인\n",
        "\n",
        "test_var = torch.FloatTensor([[73,80,75]])\n",
        "pred_y = model(test_var)\n",
        "print(\"훈련 후 입력 [73,80,75]에 대한 y 예측값: \", float(pred_y))\n",
        "print()\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5XdcZSKBkZl",
        "outputId": "64942f36-3a9d-46ba-daf8-e994717b878e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력 [73,80,75]에 대한 y 예측값:  151.2305450439453\n",
            "\n",
            "[Parameter containing:\n",
            "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2802], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. 클래스로 파이토치 모델 구현하기"
      ],
      "metadata": {
        "id": "KILjJirjCIEH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K88nN3zDCKs2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}