{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsJ+b54PlvyhlanEXe1MWh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Russel-hunho/DeepLearning/blob/main/pytorch_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. 선형 회귀(Linear Regression)"
      ],
      "metadata": {
        "id": "jvG3ezJk07Ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 가설(Hypothesis) 수립: y = H(x)\n",
        "      \n",
        "      선형회귀에선, H(x) = Wx+b\n",
        "      (W: 가중치, b: 편향(Bias))\n",
        "2. 비용함수(Cost Function) 설정 -> 최소화 하기\n",
        "3. 최적화 알고리즘 선택\n",
        "4. 손실 계산(Compute Loss)"
      ],
      "metadata": {
        "id": "REHv6vAi_z2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "비용 함수(cost function) = 손실 함수(loss function) = 오차 함수(error function) = 목적 함수(objective function)"
      ],
      "metadata": {
        "id": "nvK-12pv-uWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "옵티마이저(Optimizer) 알고리즘 = 최적화 알고리즘\n",
        "\n",
        "*   경사 하강법(Gradient Descent)\n",
        "*   항목 추가\n",
        "\n"
      ],
      "metadata": {
        "id": "bvQJ0f23-8b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 경사 하강법(Gradient Descent)\n",
        "가설: y = H(x) = Wx\n"
      ],
      "metadata": {
        "id": "wk_KgvK2_EhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "acpbmJKB_TCA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 항상 같은 결과가 나오도록 seed값 고정시키기\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDgoAnKSld6s",
        "outputId": "7230fc02-ab78-4e9c-f529-f5d5c7bb266a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc10c168bf0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rxWXEJGY0wGg"
      },
      "outputs": [],
      "source": [
        "''' [y = Wx + b] model을 학습시킬 data 설정 ''' \n",
        "\n",
        "# 변수 선언\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 가설에 사용할 가중치, 편향값의 초기값 설정'''\n",
        "\n",
        "# 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시함.\n",
        "W = torch.zeros(1, requires_grad=True) \n",
        "# 가중치 W를 출력\n",
        "print(W)\n",
        "\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "print(b)\n",
        "\n",
        "# 현재 H(x) = 0*x + 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wctSC93AlqPN",
        "outputId": "fedc7ac1-6e8d-4fc1-8abf-26b3e5351b54"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n",
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 가설 세우기 '''\n",
        "\n",
        "hypothesis = x_train * W + b\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz5uxh8Il_Gc",
        "outputId": "895e7250-6c9a-4ed2-892c-cc716f5194f1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 비용함수 선언 '''\n",
        "\n",
        "# 이번 선형회귀에선, 오차의 평균제곱으로 설정\n",
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ506v73mUnC",
        "outputId": "1c452333-7366-4449-cabd-5fe3fd1f52af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 경사하강법 구현 '''\n",
        "## SGD: 경사 하강법의 일종\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "  # lr: 학습률(Learning Rate)\n",
        "print(optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEkkxLmgmsYJ",
        "outputId": "26ddbe92-7008-4540-a062-f5af4482d6a7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient를 0으로 초기화\n",
        "optimizer.zero_grad()\n",
        "print(optimizer)\n",
        "# 비용 함수를 미분하여 gradient 계산\n",
        "cost.backward()\n",
        "print(cost)\n",
        "# W와 b를 업데이트\n",
        "optimizer.step()\n",
        "print(optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dIMHbrXm__X",
        "outputId": "9f27b4b8-af02-4ba8-ec01-496d924b1227"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 실행 코드"
      ],
      "metadata": {
        "id": "rZFusQakoDlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "## 항상 같은 결과가 나오도록 seed값 고정시키기\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "nb_epochs = 3500 # 원하는만큼 경사 하강법을 반복\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = x_train * W + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_45jDoBZoE6L",
        "outputId": "8862b743-2e09-4f76-efd3-36a418d7bc22"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/3500 W: 0.187, b: 0.080 Cost: 18.666666\n",
            "Epoch  100/3500 W: 1.746, b: 0.578 Cost: 0.048171\n",
            "Epoch  200/3500 W: 1.800, b: 0.454 Cost: 0.029767\n",
            "Epoch  300/3500 W: 1.843, b: 0.357 Cost: 0.018394\n",
            "Epoch  400/3500 W: 1.876, b: 0.281 Cost: 0.011366\n",
            "Epoch  500/3500 W: 1.903, b: 0.221 Cost: 0.007024\n",
            "Epoch  600/3500 W: 1.924, b: 0.174 Cost: 0.004340\n",
            "Epoch  700/3500 W: 1.940, b: 0.136 Cost: 0.002682\n",
            "Epoch  800/3500 W: 1.953, b: 0.107 Cost: 0.001657\n",
            "Epoch  900/3500 W: 1.963, b: 0.084 Cost: 0.001024\n",
            "Epoch 1000/3500 W: 1.971, b: 0.066 Cost: 0.000633\n",
            "Epoch 1100/3500 W: 1.977, b: 0.052 Cost: 0.000391\n",
            "Epoch 1200/3500 W: 1.982, b: 0.041 Cost: 0.000242\n",
            "Epoch 1300/3500 W: 1.986, b: 0.032 Cost: 0.000149\n",
            "Epoch 1400/3500 W: 1.989, b: 0.025 Cost: 0.000092\n",
            "Epoch 1500/3500 W: 1.991, b: 0.020 Cost: 0.000057\n",
            "Epoch 1600/3500 W: 1.993, b: 0.016 Cost: 0.000035\n",
            "Epoch 1700/3500 W: 1.995, b: 0.012 Cost: 0.000022\n",
            "Epoch 1800/3500 W: 1.996, b: 0.010 Cost: 0.000013\n",
            "Epoch 1900/3500 W: 1.997, b: 0.008 Cost: 0.000008\n",
            "Epoch 2000/3500 W: 1.997, b: 0.006 Cost: 0.000005\n",
            "Epoch 2100/3500 W: 1.998, b: 0.005 Cost: 0.000003\n",
            "Epoch 2200/3500 W: 1.998, b: 0.004 Cost: 0.000002\n",
            "Epoch 2300/3500 W: 1.999, b: 0.003 Cost: 0.000001\n",
            "Epoch 2400/3500 W: 1.999, b: 0.002 Cost: 0.000001\n",
            "Epoch 2500/3500 W: 1.999, b: 0.002 Cost: 0.000000\n",
            "Epoch 2600/3500 W: 1.999, b: 0.001 Cost: 0.000000\n",
            "Epoch 2700/3500 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 2800/3500 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 2900/3500 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 3000/3500 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 3100/3500 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3200/3500 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3300/3500 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3400/3500 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3500/3500 W: 2.000, b: 0.000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_fIKgxSopAlS"
      }
    }
  ]
}